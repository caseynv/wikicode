{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43767484-d7f1-4c80-88fc-cd83cf64fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywikibot\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import ast\n",
    "# Connect to enwiki\n",
    "enwiki = pywikibot.Site('en', 'wikipedia')\n",
    "# and then to wikidata\n",
    "enwiki_repo = enwiki.data_repository()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3396e143-dab2-4d3a-bf77-0c615059b426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Simon, Melhuish',\n",
       " 'Enrique, Villa',\n",
       " 'Beatriz, Aja',\n",
       " 'Eduardo, Artal',\n",
       " 'Richard, Battye',\n",
       " 'Diego, Herranz',\n",
       " 'Clive, Dickinson',\n",
       " 'Marcos, Lopez-Cantera',\n",
       " 'Roger, Hoyland',\n",
       " 'Juan, Cano',\n",
       " 'Lucio, Piccirillo']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "def print_authorname(list_item):\n",
    "    \n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    \n",
    "    i_list = []\n",
    "    for data_item in list_item:\n",
    "        item = pywikibot.ItemPage(repo, data_item) \n",
    "        #item_dict = item.get()\n",
    "    \n",
    "        for source in item.claims['P50']:\n",
    "            tt = list(source.qualifiers.items())\n",
    "            for key, value in tt:\n",
    "                if key == 'P1545':\n",
    "                    QID = source.target.getID()\n",
    "                    item1 = pywikibot.ItemPage(repo, QID) \n",
    "                    item_dict1 = item1.get()\n",
    "                    try:\n",
    "                        item_new = item_dict1['claims']['P735']\n",
    "                        for item1_new in item_new:\n",
    "                            itemm = item1_new.target.getID()\n",
    "                            QID1 = pywikibot.ItemPage(repo, itemm) \n",
    "                            name = QID1.get()\n",
    "                            try:\n",
    "                                item_new1 = item_dict1['claims']['P734']\n",
    "                                for item1_new1 in item_new1:\n",
    "                                    itemm1 = item1_new1.target.getID()\n",
    "                                    QID2 = pywikibot.ItemPage(repo, itemm1) \n",
    "                                    name1 = QID2.get()\n",
    "                                    m_list = name['labels']['en'] + ', ' + name1['labels']['en']\n",
    "                                    i_list.append(m_list)\n",
    "                            except:\n",
    "                                print('No Family name')\n",
    "                    except:\n",
    "                        print('No Given name')\n",
    "                    \n",
    "                    \n",
    "    return i_list\n",
    "\n",
    "print_authorname(['Q60868120'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a87b824-0bc0-4882-97fc-2ecb686ea8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '20',\n",
       " '21',\n",
       " '24',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "#function to get the cordinal number of author strings p2093\n",
    "\n",
    "def print_authorstring_info(list_item):\n",
    "    \n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    \n",
    "    o_list = []\n",
    "    for data_item in list_item:\n",
    "        item = pywikibot.ItemPage(repo, data_item) \n",
    "        #item_dict = item.get()\n",
    "    \n",
    "        for sourc in item.claims['P2093']:\n",
    "            stat = list(sourc.qualifiers.items())\n",
    "                    \n",
    "            for keyy, valuee in stat:\n",
    "                if keyy == 'P1545':\n",
    "                    num = valuee[0].getTarget()\n",
    "                    o_list.append(num)\n",
    "                    \n",
    "                \n",
    "    return o_list\n",
    "                    \n",
    "print_authorstring_info(['Q60868120'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74116925-a7ca-4b34-a79f-388be9e7d025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40', '29', '23', '22', '31', '18', '36', '19', '7', '25', '30']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "#function to get the cordinal number of authors p50\n",
    "\n",
    "def print_author_info(list_item):\n",
    "    \n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    \n",
    "    q = []\n",
    "    for data_item in list_item:\n",
    "        item = pywikibot.ItemPage(repo, data_item) \n",
    "        item_dict = item.get()\n",
    "    \n",
    "        for claim in item_dict['claims']: # Loop through items\n",
    "            if claim == 'P50':\n",
    "                for source in item.claims[claim]:\n",
    "                    \n",
    "                    tt = list(source.qualifiers.items())\n",
    "                    for key, value in tt:\n",
    "                        if key == 'P1545':\n",
    "                            no1 = value[0].getTarget()\n",
    "                            q.append(no1)\n",
    "                                \n",
    "                            \n",
    "    return q\n",
    "\n",
    "print_author_info(['Q60868120'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77076847-924e-486c-a0e9-20a62103cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "#function to concatenate the list of cordinal number of authors and author strings \n",
    "\n",
    "def all_authors():\n",
    "    \n",
    "    f = print_author_info(['Q60868120'])\n",
    "    j = print_authorstring_info(['Q60868120'])\n",
    "    k = j + f\n",
    "    return k\n",
    "    \n",
    "all_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ba1ce79-2a8e-4e38-9a1f-9cd9ce5c7c00",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: <_ast.Name object at 0x7fc4ea77c790>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(useful)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m#ti = re.match('citation_author', text3)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m#for text in text3:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;66;03m#tip = text['content']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;66;03m#list1.append(tip)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#return list1\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mauthor_citation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://api.crossref.org/v1/works/10.1007/BF02986634\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36mauthor_citation\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      7\u001b[0m html \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      8\u001b[0m str1 \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m useful \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr1\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(useful)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:99\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:88\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     87\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[1;32m     91\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:88\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     87\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[1;32m     91\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:88\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     87\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[1;32m     91\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:98\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:75\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:66\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/usr/lib/python3.8/ast.py:63\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_malformed_node\u001b[39m(node):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalformed node or string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: <_ast.Name object at 0x7fc4ea77c790>"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#This function extracts author names from bibtex \n",
    "\n",
    "def author_citation(url):\n",
    "    list1 = []\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        html = response.read()\n",
    "        str1 = html.decode(\"UTF-8\")\n",
    "        useful = repr(ast.literal_eval(str1))\n",
    "        print(useful)\n",
    "        #ti = re.match('citation_author', text3)\n",
    "        #for text in text3:\n",
    "            #tip = text['content']\n",
    "            #m = re.match(r\"(?P<first_name>\\w+) (?P<last_name>\\w+)\", tip)\n",
    "            #t = m.group('first_name')\n",
    "            #p = m.group('last_name')\n",
    "            #t = re.match(r'^(.+\\.)+\\s+(.+)$', tip)\n",
    "            #new_list = list(t.groups())\n",
    "            #list1.append(new_list)\n",
    "        \n",
    "        #for lis in list1:\n",
    "            #print('name: '+ lis[0])\n",
    "            #f_name = new_list[0]\n",
    "            #l_name = new_list[1]\n",
    "            \n",
    "            #list1.append(tip)\n",
    "    #return list1\n",
    "\n",
    "author_citation('https://api.crossref.org/v1/works/10.1007/BF02986634')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0cb86f-1707-4fd5-b458-0e4a0468a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#This function matches the name sof the authors in the citation to their cordinal no\n",
    "\n",
    "def author_match():\n",
    "    stated = all_authors()\n",
    "    authorname = author_citation('https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8444/1/The-QUIJOTE-CMB-experiment--studying-the-polarisation-of-the/10.1117/12.926581.full?SSO=1')\n",
    "    #for r in stated:\n",
    "        #num_r = int(r)\n",
    "    new_list = [authorname[int(i) - 1] for i in stated]\n",
    "    return new_list\n",
    "author_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25f6eb-d88b-4c0e-b53e-c043fadf2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#This function adds the author string name to a list\n",
    "\n",
    "def print_authorstring(list_item):\n",
    "    ti = []\n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    for data_item in list_item:\n",
    "        item = pywikibot.ItemPage(repo, data_item) \n",
    "        item_dict = item.get()\n",
    "    \n",
    "        for claim in item_dict['claims']: # Loop through items\n",
    "            if claim == 'P2093':\n",
    "                try:\n",
    "                    for source in item.claims[claim]:\n",
    "                        QID = source.target\n",
    "                        ti.append(QID)\n",
    "                        \n",
    "                except:\n",
    "                    print('Name')\n",
    "    return ti\n",
    "\n",
    "print_authorstring(['Q60868120'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6bd21-3de0-4018-a54f-f007e7c20304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#This function joins the authorstring name and the concatenated given and family name \n",
    "\n",
    "def joined():\n",
    "    first = print_authorstring(['Q60868120'])\n",
    "    second = print_authorname(['Q60868120'])\n",
    "    k = first + second\n",
    "    \n",
    "    return k\n",
    "joined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51804baa-1aa6-4112-8f4e-01a8d2c1ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citation names - wikidata names\n",
      "\n",
      "\n",
      "J. A. Rubiño-Martín - J. A. Rubiño-Martín\n",
      "R. Rebolo - R. Rebolo\n",
      "M. Aguiar - M. Aguiar\n",
      "R. Génova-Santos - R. Génova-Santos\n",
      "F. Gómez-Reñasco - F. Gómez-Reñasco\n",
      "J. M. Herreros - J. M. Herreros\n",
      "C. López-Caraballo - C. López-Caraballo\n",
      "A. E. Pelaez Santos - A. E. Pelaez Santos\n",
      "V. Sanchez de la Rosa - V. Sanchez de la Rosa\n",
      "A. Vega-Moreno - A. Vega-Moreno\n",
      "T. Viera-Curbelo - T. Viera-Curbelo\n",
      "E. Martínez-Gonzalez - E. Martínez-Gonzalez\n",
      "R. B. Barreiro - R. B. Barreiro\n",
      "F. J. Casas - F. J. Casas\n",
      "J. M. Diego - J. M. Diego\n",
      "R. Fernández-Cobos - R. Fernández-Cobos\n",
      "D. Ortiz - D. Ortiz\n",
      "P. Vielva - P. Vielva\n",
      "J. Cagigas - J. Cagigas\n",
      "L. de la Fuente - L. de la Fuente\n",
      "A. Mediavilla - A. Mediavilla\n",
      "J. V. Terán - J. V. Terán\n",
      "E. Blackhurst - E. Blackhurst\n",
      "M. Brown - M. Brown\n",
      "R. D. Davies - R. D. Davies\n",
      "R. J. Davis - R. J. Davis\n",
      "S. Harper - S. Harper\n",
      "B. Maffei - B. Maffei\n",
      "M. McCulloch - M. McCulloch\n",
      "G. Pisano - G. Pisano\n",
      "R. A. Watson - R. A. Watson\n",
      "M. Hobson - M. Hobson\n",
      "K. Grainge - K. Grainge\n",
      "A. Lasenby - A. Lasenby\n",
      "R. Saunders - R. Saunders\n",
      "P. Scott - P. Scott\n",
      "S. Melhuish - Simon, Melhuish\n",
      "E. Villa - Enrique, Villa\n",
      "B. Aja - Beatriz, Aja\n",
      "E. Artal - Eduardo, Artal\n",
      "R. Battye - Richard, Battye\n",
      "D. Herranz - Diego, Herranz\n",
      "C. Dickinson - Clive, Dickinson\n",
      "M. López-Caniego - Marcos, Lopez-Cantera\n",
      "R. J. Hoyland - Roger, Hoyland\n",
      "J. L. Cano - Juan, Cano\n",
      "L. Piccirillo - Lucio, Piccirillo\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#This function adds matches the names in the wikidata and citation \n",
    "\n",
    "def match_alt():\n",
    "    left = author_match()\n",
    "    right = joined()\n",
    "    \n",
    "    print('citation names' + ' - ' + 'wikidata names')\n",
    "    print('\\n')\n",
    "    for left1, right1 in zip(left, right):\n",
    "        if left.index(left1) == right.index(right1):\n",
    "    \n",
    "            print(left1[0] + ' ' + left1[1] + ' - ' + right1 )\n",
    "match_alt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77e665-f7dd-4664-8148-66b1d669294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#This function adds the claims in P2093 and P50-useful to add qualifiers\n",
    "\n",
    "def join_names():\n",
    "    \n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    item = pywikibot.ItemPage(repo, 'Q60868120') \n",
    "    item_dict = item.get()\n",
    "    \n",
    "    pli = []\n",
    "    pli1 = []\n",
    "         \n",
    "    if 'P50' in item_dict['claims']:\n",
    "        for sourcee in item.claims['P50']:\n",
    "            tt = list(sourcee.qualifiers.items())\n",
    "            for key, value in tt:\n",
    "                if key == 'P1545':\n",
    "                    #no1 = value[0].getTarget()\n",
    "                    pli.append(sourcee)\n",
    "    else:\n",
    "        pli = []\n",
    "    if 'P2093' in item_dict['claims']:\n",
    "        for claim in item_dict['claims']['P2093']: \n",
    "            pli1.append(claim)\n",
    "    else:\n",
    "        pli1 = []\n",
    "        \n",
    "    joined = pli1 + pli\n",
    "    return joined\n",
    "\n",
    "join_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "777b86af-2544-41e7-b5c8-7aee0fa5a8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9688!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.7 seconds, 2022-04-16 16:43:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9687!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.7 seconds, 2022-04-16 16:43:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9688!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.6 seconds, 2022-04-16 16:43:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9687!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.6 seconds, 2022-04-16 16:43:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9688!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.6 seconds, 2022-04-16 16:43:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9687!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.6 seconds, 2022-04-16 16:43:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9688!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.6 seconds, 2022-04-16 16:44:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9687!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.6 seconds, 2022-04-16 16:44:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9688!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sleeping for 9.7 seconds, 2022-04-16 16:44:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Qualifier for P9687!\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#This function adds the P9688 and P9687 qualifier if not present\n",
    "\n",
    "def add_namesqualifier(data_item):\n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    item = pywikibot.ItemPage(repo, data_item) \n",
    "    item_dict = item.get()\n",
    "    listb = join_names()\n",
    "    dateCre = author_match()\n",
    "    \n",
    "    for te, tea in zip(listb, dateCre):\n",
    "        \n",
    "        if listb.index(te) == dateCre.index(tea):\n",
    "            if 'P9688' not in te.qualifiers:\n",
    "                qualifier = pywikibot.Claim(repo, u'P9688')\n",
    "                qualifier.setTarget(tea[1])\n",
    "                te.addQualifier(qualifier, summary=u'Adding a qualifier.')\n",
    "                print('New Qualifier for P9688!')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if 'P9687' not in te.qualifiers:\n",
    "                qualifier = pywikibot.Claim(repo, u'P9687')\n",
    "                qualifier.setTarget(tea[0])\n",
    "                te.addQualifier(qualifier, summary=u'Adding a qualifier.')\n",
    "                print('New Qualifier for P9687!')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "add_namesqualifier('Q60868120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf7fd5-b614-4869-b5eb-03fc39f985b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function ensures the claim without a series ordinal is not included \n",
    "\n",
    "def print_claim1(list_item):\n",
    "    \n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    \n",
    "    state = []\n",
    "    for data_item in list_item:\n",
    "        item = pywikibot.ItemPage(repo, data_item) \n",
    "        item_dict = item.get()\n",
    "    \n",
    "        for claim in item_dict['claims']['P50']: # Loop through items\n",
    "            nu = claim.qualifiers.items()\n",
    "            for t, y in nu:\n",
    "                if t == 'P1545':\n",
    "                    state.append(claim)\n",
    "    return state\n",
    "                \n",
    "print_claim1(['Q60868120'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c06a6238-0edd-4ee0-a1aa-ae86a2860360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#This function adds the statedin qualifier if not present\n",
    "\n",
    "def add_statedqualifier(list_item):\n",
    "    \n",
    "    site = pywikibot.Site(\"wikidata\", \"wikidata\")\n",
    "    repo = site.data_repository()\n",
    "    neu = print_author_info(['Q60868120'])\n",
    "    names = author_citation('https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8444/1/The-QUIJOTE-CMB-experiment--studying-the-polarisation-of-the/10.1117/12.926581.full?SSO=1')\n",
    "    claim_list = print_claim1(['Q60868120'])\n",
    "    \n",
    "    teb = [names[int(i) - 1] for i in neu]\n",
    "    for u, p in zip(teb, claim_list):\n",
    "        \n",
    "        if claim_list.index(p) == teb.index(u):\n",
    "            \n",
    "            if 'P1932' not in p.qualifiers:\n",
    "                qualifier = pywikibot.Claim(repo, u'P1932')\n",
    "                qualifier.setTarget(u)\n",
    "                p.addQualifier(qualifier, summary=u'Adding a qualifier.')\n",
    "                print('New Qualifier for P1932!')\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "add_statedqualifier(['Q60868120'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec53844-f0a2-4b33-831b-e6646f242d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
